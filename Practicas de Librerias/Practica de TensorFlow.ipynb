{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 32s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "imdb = tf.keras.datasets.imdb.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de modelo de tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y preparar el conjunto de datos MNIST\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 #Normaliza los datos, los pixel tienen 255 espacios, por eso el 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2932 - accuracy: 0.9138\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1445 - accuracy: 0.9578\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1061 - accuracy: 0.9679\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0883 - accuracy: 0.9729\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0747 - accuracy: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x18b629c3290>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0802 - accuracy: 0.9766 - 816ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0801958292722702, 0.9765999913215637]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n",
      "El modelo predice que el dígito es: 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Selecciona una imagen del conjunto de prueba\n",
    "img = x_test[1532]\n",
    "\n",
    "# Muestra la imagen\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Expande las dimensiones de la imagen para que se ajuste al modelo\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Haz una predicción\n",
    "predictions = model.predict(img)  # Usa el model que se preparo antes!\n",
    "\n",
    "# Interpreta la predicción\n",
    "predicted_digit = np.argmax(predictions)\n",
    "print(f\"El modelo predice que el dígito es: {predicted_digit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso con TensorFlow y CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y preparar el conjunto de datos CIFAR-10\n",
    "(x_train2, y_train2), (x_test2, y_test2) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train2, x_test2 = x_train2 / 255.0, x_test2 / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo\n",
    "model2 = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 29s 17ms/step - loss: 1.5516 - accuracy: 0.4342 - val_loss: 1.3604 - val_accuracy: 0.5221\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 1.1795 - accuracy: 0.5790 - val_loss: 1.0842 - val_accuracy: 0.6148\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 32s 21ms/step - loss: 1.0252 - accuracy: 0.6415 - val_loss: 1.1087 - val_accuracy: 0.6147\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 28s 18ms/step - loss: 0.9302 - accuracy: 0.6720 - val_loss: 0.9610 - val_accuracy: 0.6633\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8576 - accuracy: 0.6986 - val_loss: 0.9202 - val_accuracy: 0.6782\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 29s 19ms/step - loss: 0.8046 - accuracy: 0.7179 - val_loss: 0.8979 - val_accuracy: 0.6884\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7531 - accuracy: 0.7355 - val_loss: 0.8918 - val_accuracy: 0.6931\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.7106 - accuracy: 0.7492 - val_loss: 0.8541 - val_accuracy: 0.7103\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 26s 17ms/step - loss: 0.6736 - accuracy: 0.7646 - val_loss: 0.8530 - val_accuracy: 0.7131\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 27s 17ms/step - loss: 0.6352 - accuracy: 0.7756 - val_loss: 0.8982 - val_accuracy: 0.7045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x18b06461990>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "model2.fit(x_train2, y_train2, epochs=10, \n",
    "          validation_data=(x_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.8982 - accuracy: 0.7045 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8982100486755371, 0.7045000195503235]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "model2.evaluate(x_test2, y_test2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. IMDB\n",
    "IMDB es un conjunto de datos para el análisis de sentimientos, compuesto por 25,000 críticas de películas para entrenamiento y 25,000 críticas para prueba. Las críticas están etiquetadas como positivas o negativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 5s - loss: 0.5191 - accuracy: 0.7670 - val_loss: 0.3359 - val_accuracy: 0.8702 - 5s/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "782/782 - 3s - loss: 0.2656 - accuracy: 0.8994 - val_loss: 0.2823 - val_accuracy: 0.8846 - 3s/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "782/782 - 3s - loss: 0.2075 - accuracy: 0.9223 - val_loss: 0.2818 - val_accuracy: 0.8839 - 3s/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "782/782 - 3s - loss: 0.1730 - accuracy: 0.9367 - val_loss: 0.2911 - val_accuracy: 0.8827 - 3s/epoch - 4ms/step\n",
      "Epoch 5/10\n",
      "782/782 - 3s - loss: 0.1488 - accuracy: 0.9482 - val_loss: 0.3167 - val_accuracy: 0.8768 - 3s/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "782/782 - 3s - loss: 0.1294 - accuracy: 0.9568 - val_loss: 0.3347 - val_accuracy: 0.8748 - 3s/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "782/782 - 3s - loss: 0.1135 - accuracy: 0.9627 - val_loss: 0.3629 - val_accuracy: 0.8714 - 3s/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "782/782 - 3s - loss: 0.1006 - accuracy: 0.9684 - val_loss: 0.3991 - val_accuracy: 0.8690 - 3s/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "782/782 - 3s - loss: 0.0884 - accuracy: 0.9737 - val_loss: 0.4235 - val_accuracy: 0.8644 - 3s/epoch - 4ms/step\n",
      "Epoch 10/10\n",
      "782/782 - 3s - loss: 0.0789 - accuracy: 0.9776 - val_loss: 0.4603 - val_accuracy: 0.8603 - 3s/epoch - 4ms/step\n",
      "782/782 - 1s - loss: 0.4603 - accuracy: 0.8603 - 963ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46033960580825806, 0.860319972038269]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, preprocessing\n",
    "\n",
    "# Cargar y preparar el conjunto de datos IMDB\n",
    "(x_train3, y_train3), (x_test3, y_test3) = tf.keras.datasets.imdb.load_data(num_words=10000)\n",
    "\n",
    "# Preprocesar los datos\n",
    "x_train3 = preprocessing.sequence.pad_sequences(x_train3, maxlen=256)\n",
    "x_test3 = preprocessing.sequence.pad_sequences(x_test3, maxlen=256)\n",
    "\n",
    "# Definir el modelo\n",
    "model3 = models.Sequential([\n",
    "    layers.Embedding(10000, 16),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model3.fit(x_train3, y_train3, epochs=10, \n",
    "          validation_data=(x_test3, y_test3), \n",
    "          verbose=2)\n",
    "\n",
    "# Evaluar el modelo\n",
    "model3.evaluate(x_test3, y_test3, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at imdb_sentiment_analysis_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m review_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEsta película fue realmente genial. Me encantó cada momento de ella.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Cargar el modelo previamente entrenado\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m model3 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimdb_sentiment_analysis_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Tokenizar la revisión (convertir palabras en índices)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m word_index \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mimdb\u001b[38;5;241m.\u001b[39mget_word_index()\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    255\u001b[0m         filepath,\n\u001b[0;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m         )\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m    240\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[0;32m    241\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at imdb_sentiment_analysis_model.h5"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Definir la revisión que queremos analizar\n",
    "review_text = \"Esta película fue realmente genial. Me encantó cada momento de ella.\"\n",
    "\n",
    "# Cargar el modelo previamente entrenado\n",
    "model3 = tf.keras.models.load_model('imdb_sentiment_analysis_model.h5')\n",
    "\n",
    "# Tokenizar la revisión (convertir palabras en índices)\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "words = review_text.lower().split()\n",
    "review_sequence = [word_index[word] if word in word_index and word_index[word] < 10000 else 0 for word in words]\n",
    "\n",
    "# Asegurarse de que la revisión tenga la misma longitud que las revisiones de entrenamiento\n",
    "review_sequence = pad_sequences([review_sequence], maxlen=256)\n",
    "\n",
    "# Hacer la predicción\n",
    "prediction = model3.predict(review_sequence)\n",
    "\n",
    "# Interpretar la predicción\n",
    "sentiment = \"positivo\" if prediction > 0.5 else \"negativo\"\n",
    "confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(f\"Sentimiento de la revisión: {sentiment} (confianza: {confidence:.2f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
